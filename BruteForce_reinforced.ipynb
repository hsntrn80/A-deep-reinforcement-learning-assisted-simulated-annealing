{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellNumber(n): \n",
    "  \n",
    "    bell = [[0 for i in range(n+1)] for j in range(n+1)] \n",
    "    bell[0][0] = 1\n",
    "    for i in range(1, n+1): \n",
    "  \n",
    "        # Explicitly fill for j = 0 \n",
    "        bell[i][0] = bell[i-1][i-1] \n",
    "  \n",
    "        # Fill for remaining values of j \n",
    "        for j in range(1, i+1): \n",
    "            bell[i][j] = bell[i-1][j-1] + bell[i][j-1] \n",
    "  \n",
    "    return bell[n][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bell Number 0 is 1\nBell Number 1 is 1\nBell Number 2 is 2\nBell Number 3 is 5\nBell Number 4 is 15\nBell Number 5 is 52\nBell Number 6 is 203\nBell Number 7 is 877\nBell Number 8 is 4140\nBell Number 9 is 21147\nBell Number 10 is 115975\nBell Number 11 is 678570\nBell Number 12 is 4213597\nBell Number 13 is 27644437\nBell Number 14 is 190899322\nBell Number 15 is 1382958545\nBell Number 16 is 10480142147\nBell Number 17 is 82864869804\nBell Number 18 is 682076806159\nBell Number 19 is 5832742205057\nBell Number 20 is 51724158235372\n"
     ]
    }
   ],
   "source": [
    "for n in range(21): \n",
    "    print('Bell Number', n, 'is', bellNumber(n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 [[1, 2, 3]]\n2 [[1], [2, 3]]\n3 [[1, 2], [3]]\n4 [[1, 3], [2]]\n5 [[1], [2], [3]]\n"
     ]
    }
   ],
   "source": [
    "def partition(collection):\n",
    "    if len(collection) == 1:\n",
    "        yield [ collection ]\n",
    "        return\n",
    "\n",
    "    first = collection[0]\n",
    "    for smaller in partition(collection[1:]):\n",
    "        # insert `first` in each of the subpartition's subsets\n",
    "        for n, subset in enumerate(smaller):\n",
    "            yield smaller[:n] + [[ first ] + subset]  + smaller[n+1:]\n",
    "        # put `first` in its own subset \n",
    "        yield [ [ first ] ] + smaller\n",
    "\n",
    "\n",
    "something = list(range(1,4))\n",
    "\n",
    "for n, p in enumerate(partition(something), 1):\n",
    "    print(n, sorted(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#This version is same as earlier version _v3\n",
    "# There are 4 possible variants of _vs\n",
    "# Initial population: Restricted, Unrestricted\n",
    "# Mutation: Switch only, Switch and Open new Cluster\n",
    "####This version Unrestricted + Switch Only ######\n",
    "# For all variants we use following GA parameters:\n",
    "# Population: 100\n",
    "# Generation:25\n",
    "# Crossover:0.8\n",
    "# Mutation:0.4\n",
    "# Gene Mutation:0.4 \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T  \n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import concurrent.futures as cf\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "\n",
    "from reinforce import *\n",
    "\n",
    "\n",
    "# reproducability\n",
    "random.seed(60)\n",
    "np.random.seed(60)\n",
    "torch.manual_seed(60)\n",
    "\n",
    "\n",
    "def generateVectorsFixedSum(m, n):\n",
    "    \"\"\" generator for all combinations of $w$ for given number of servers and\n",
    "     classes \"\"\"\n",
    "    if m == 1:\n",
    "        yield [n]\n",
    "    else:\n",
    "        for i in range(n + 1):\n",
    "            for vect in generateVectorsFixedSum(m - 1, n - i):\n",
    "                yield [i] + vect\n",
    "\n",
    "\n",
    "def MMCsolver(lamda, mu, nservers, mClasses):\n",
    "    assert sum(lamda/mu) < nservers  # ensure stability\n",
    "\n",
    "    # initialize \\Lamda and \\alpha\n",
    "    lambdaTot = sum(lamda)\n",
    "    alpha = lamda/lambdaTot\n",
    "\n",
    "    # create mapping between the combination vectors and matrix columns/rows\n",
    "    idx_map = dict([(tuple(vect), i)\n",
    "                    for i,\n",
    "                    vect in enumerate(generateVectorsFixedSum(mClasses, nservers))])\n",
    "    # need to use tuple here as 'list' cannot be as a key\n",
    "    i_map = dict([(idx_map[idx], list(idx)) for idx in idx_map])\n",
    "    # need to use list here as 'tuple' cannot be modified as will be need further\n",
    "\n",
    "    # function to get matrix index based on the system state\n",
    "    def getIndexDict(idx, idx_map):\n",
    "        try:\n",
    "            return idx_map[tuple(idx)]\n",
    "        except KeyError:\n",
    "            return -1\n",
    "    # generate matrices A_0 and A_1\n",
    "    q_max = len(idx_map)\n",
    "    A0 = np.zeros((q_max, q_max))  # corresponds to terms with i items in queue\n",
    "    A1 = np.zeros((q_max, q_max))  # corresponds to terms with i+1 items in queue\n",
    "    for i, idx in i_map.items():\n",
    "        # diagonal term\n",
    "        A0[i, i] += 1 + np.sum(idx*mu)/lambdaTot\n",
    "\n",
    "    # term corresponding to end of service for item j1, start of service for j2\n",
    "        for j1 in range(mClasses):\n",
    "            for j2 in range(mClasses):\n",
    "                idx[j1] += 1\n",
    "                idx[j2] -= 1\n",
    "                i1 = getIndexDict(idx, idx_map)  # convert 'list' back to tuple to use it as a key\n",
    "                if i1 >= 0:\n",
    "                    A1[i, i1] += alpha[j2]/lambdaTot*idx[j1]*mu[j1]\n",
    "                idx[j1] -= 1\n",
    "                idx[j2] += 1\n",
    "\n",
    "    # compute matrix Z iteratively\n",
    "    eps = 0.00000001\n",
    "    I = np.eye(q_max)  # produces identity matrix\n",
    "    Z_prev = np.zeros((q_max, q_max))\n",
    "    delta = 1\n",
    "    A0_inv = np.linalg.inv(A0)\n",
    "    while delta > eps:\n",
    "        Z = np.dot(A0_inv, I + np.dot(A1, np.dot(Z_prev, Z_prev)))  # invA0*(I+A1*Z*Z)\n",
    "        delta = np.sum(np.abs(Z-Z_prev))\n",
    "        Z_prev = Z\n",
    "\n",
    "    # generate Q matrices, it will be stored in a list\n",
    "    Q = []\n",
    "    idxMat = []  # matrix with server occupancy for each system state, will be used in computing the system parameters\n",
    "    Q.insert(0, Z[:])\n",
    "    idxMat.insert(0, np.array([x for x in i_map.values()]))\n",
    "\n",
    "    i_map_full = []\n",
    "    i_map_full.append(i_map)\n",
    "\n",
    "    # dict([ (tuple(vect), i) for i, vect in enumerate(generateVectorsFixedSum(mClasses, nServers)) ])\n",
    "    idx_map_nplus = idx_map\n",
    "    i_map_nplus = i_map  # dict([(idx_map_nplus[idx], list(idx)) for idx in idx_map_nplus ])\n",
    "    q_max_nplus = len(idx_map_nplus)\n",
    "\n",
    "    idx_map_n = idx_map_nplus\n",
    "    i_map_n = i_map_nplus\n",
    "    q_max_n = q_max_nplus\n",
    "\n",
    "    A1_n = A1[:]\n",
    "\n",
    "    for n in range(nservers, 0, -1):\n",
    "        idx_map_nminus = dict([(tuple(vect), i)\n",
    "                               for i, vect in enumerate(generateVectorsFixedSum(mClasses, n-1))])\n",
    "        i_map_nminus = dict([(idx_map_nminus[idx], list(idx)) for idx in idx_map_nminus])\n",
    "        q_max_nminus = len(idx_map_nminus)\n",
    "\n",
    "        i_map_full.insert(0, i_map_nminus)\n",
    "\n",
    "        L_n = np.zeros((q_max_n, q_max_nminus))  # corresponds to terms with i items in queue\n",
    "        A0_n = np.zeros((q_max_n, q_max_n))  # corresponds to terms with i items in queue\n",
    "        for i, idx in i_map_n.items():\n",
    "\n",
    "            # diagonal term\n",
    "            A0_n[i, i] += 1 + np.sum(idx*mu)/lambdaTot\n",
    "\n",
    "            # term corresponding to arrival of item item j1\n",
    "            for j2 in range(mClasses):\n",
    "                idx[j2] -= 1\n",
    "                i2 = getIndexDict(idx, idx_map_nminus)\n",
    "                if i2 >= 0:\n",
    "                    L_n[i, i2] += alpha[j2]\n",
    "                idx[j2] += 1\n",
    "\n",
    "        # Q_n = (A_0 - A_1*Q_{n+1})^{-1}*L_n\n",
    "        Q.insert(0, np.dot(np.linalg.inv(A0_n-np.dot(A1_n, Q[0])), L_n))\n",
    "\n",
    "        idx_map_nplus = idx_map_n\n",
    "        i_map_nplus = i_map_n\n",
    "        q_max_nplus = q_max_n\n",
    "\n",
    "        idx_map_n = idx_map_nminus\n",
    "        i_map_n = i_map_nminus\n",
    "        q_max_n = q_max_nminus\n",
    "        idxMat.insert(0, np.array([x for x in i_map_n.values()]))\n",
    "\n",
    "        A1_n = np.zeros((q_max_n, q_max_nplus))  # corresponds to terms with i+1 items in queue\n",
    "        for i, idx in i_map_n.items():\n",
    "            # term corresponding to end of service for item j1\n",
    "            for j1 in range(mClasses):\n",
    "                idx[j1] += 1\n",
    "                i1 = getIndexDict(idx, idx_map_nplus)\n",
    "                if i1 >= 0:\n",
    "                    A1_n[i, i1] += idx[j1]*mu[j1]/lambdaTot\n",
    "                idx[j1] -= 1\n",
    "\n",
    "    # compute the P_n for n<k and normalize it such that sum(P_n) = 1\n",
    "    P = []\n",
    "    P.append([1.0])\n",
    "\n",
    "    sm = 1.0\n",
    "    for n in range(nservers):\n",
    "        P.append(np.dot(Q[n], P[-1]))\n",
    "        sm += sum(P[-1])\n",
    "\n",
    "    sm += sum(np.dot(np.linalg.inv(np.eye(len(P[-1])) - Z), np.dot(Z, P[-1])))\n",
    "\n",
    "    for p in P:\n",
    "        p[:] /= sm  # normalization\n",
    "\n",
    "    # compute totals needed for the E[Q_i] - marginal distributions\n",
    "    inv1minZ = np.linalg.inv(np.eye(len(P[-1])) - Z)\n",
    "    EQTotal = sum(np.dot(np.dot(np.dot(inv1minZ, inv1minZ), Z), P[-1]))\n",
    "    EQQmin1Total = 2 *         sum(np.dot(np.dot(np.dot(np.dot(np.dot(inv1minZ, inv1minZ), inv1minZ), Z), Z), P[-1]))\n",
    "    EQ2Total = EQQmin1Total + EQTotal\n",
    "\n",
    "    # compute 1st and 2nd marginal moments of the numbers in the queue E[Q_i] and E[Q_i^2]\n",
    "    EQ = alpha*EQTotal\n",
    "    EQQmin1 = alpha*alpha*EQQmin1Total\n",
    "    EQ2 = EQQmin1 + EQ\n",
    "\n",
    "    # compute 1st and 2nd marginal moments of the numbers in the system E[N_i] and E[N_i^2]\n",
    "    ENTotal = EQTotal + sum(lamda/mu)\n",
    "    EN = EQ + lamda/mu\n",
    "\n",
    "    # TODO compute the E[N_i^2]\n",
    "    ES2 = np.zeros(mClasses)\n",
    "    for (p, idx) in zip(P[:-1], idxMat[:-1]):\n",
    "        ES2 += np.dot(p, idx**2)\n",
    "    ES2 += np.dot(np.dot(inv1minZ, P[-1]), idxMat[-1]**2)\n",
    "\n",
    "    ESq = alpha*np.dot(np.dot(np.dot(np.dot(inv1minZ, inv1minZ), Z), P[-1]), idxMat[-1])\n",
    "\n",
    "    EN2 = EQ2 + 2*ESq + ES2\n",
    "\n",
    "    # compute marginal variances of the numbers in the queue Var[Q_i] and in the system Var[N_i]\n",
    "    VarQTotal = EQ2Total - EQTotal**2\n",
    "    VarQ = EQ2 - EQ**2\n",
    "\n",
    "    VarN = EN2 - EN**2\n",
    "\n",
    "    # computeMarginalDistributions\n",
    "    qmax = 1500\n",
    "\n",
    "    marginalN = np.zeros((mClasses, qmax))\n",
    "\n",
    "    for m in range(mClasses):\n",
    "        for imap, p in zip(i_map_full[:-1], P[:-1]):\n",
    "            for i, idx in imap.items():\n",
    "                marginalN[m, idx[m]] += p[i]\n",
    "\n",
    "        inv1minAlphaZ = np.linalg.inv(np.eye(len(P[-1])) - (1-alpha[m])*Z)\n",
    "        frac = np.dot(alpha[m]*Z, inv1minAlphaZ)\n",
    "        # tmp = np.dot(self.Z, self.P[-1])\n",
    "        # tmp = np.dot(inv1minAlphaZ, tmp)\n",
    "        tmp = np.dot(inv1minAlphaZ, P[-1])\n",
    "\n",
    "        for q in range(0, qmax):\n",
    "            for i, idx in i_map_full[-1].items():\n",
    "                if idx[m]+q < qmax:\n",
    "                    marginalN[m, idx[m]+q] += tmp[i]\n",
    "            tmp = np.dot(frac, tmp)\n",
    "    return marginalN, EN, VarN\n",
    "\n",
    "\n",
    "def whittApprox(E1, E2, E3):\n",
    "    '''\n",
    "    input: first 3 moments of hyperexpo dist.\n",
    "    returns: parameters of hyperexpo (p, v1 and v2)\n",
    "    uses whitt approximation.....\n",
    "    '''\n",
    "    x = E1*E3-1.5*E2**2\n",
    "    # print x\n",
    "    assert x >= 0.0\n",
    "\n",
    "    y = E2-2*(E1**2)\n",
    "    # print y\n",
    "    assert y >= 0.0\n",
    "\n",
    "    Ev1 = ((x+1.5*y**2+3*E1**2*y)+math.sqrt((x+1.5*y**2-3*E1**2*y)**2+18*(E1**2)*(y**3)))/(6*E1*y)\n",
    "    # print Ev1\n",
    "    assert Ev1 >= 0\n",
    "\n",
    "    Ev2 = ((x+1.5*y**2+3*E1**2*y)-math.sqrt((x+1.5*y**2-3*E1**2*y)**2+18*(E1**2)*(y**3)))/(6*E1*y)\n",
    "    assert Ev2 >= 0\n",
    "\n",
    "    p = (E1-Ev2)/(Ev1-Ev2)\n",
    "    assert p >= 0\n",
    "\n",
    "    return 1.0/Ev1, 1.0/Ev2, p\n",
    "\n",
    "\n",
    "def isServiceRateEqual(mu):\n",
    "    return len(set(mu)) <= 1\n",
    "\n",
    "\n",
    "def Approx_MMCsolver(lamda, mu, nServers, mClasses):\n",
    "    '''\n",
    "    inputs: lamda->failure rates of SKUs\n",
    "            mu ->service rates of servers for SKUs\n",
    "            nServers->number of servers in repairshop\n",
    "            mClasses->number of SKUs := length of failure rates\n",
    "    output: Marginal Queue length for each type of SKU\n",
    "            Expected Queue length  ''  ''   ''   ''\n",
    "            Variance of Queue length ''  '' ''   ''\n",
    "    solution: Approximate 3 class system and calls MMCsolver\n",
    "    '''\n",
    "\n",
    "    marginalN = []\n",
    "    EN = []\n",
    "    VarN = []\n",
    "\n",
    "    for mCl in range(mClasses):\n",
    "        # first moment for service time distribution for approximation:\n",
    "        E_S1 = (np.inner(lamda, 1/mu)-(lamda[mCl]*1/mu[mCl]))/(sum(lamda)-lamda[mCl])  # checked\n",
    "\n",
    "        # second moment\n",
    "        E_S2 = 2*(np.inner(lamda, (1/mu)**2) -\n",
    "                  (lamda[mCl]*(1/mu[mCl])**2))/(sum(lamda)-lamda[mCl])  # checked\n",
    "\n",
    "        # third moment\n",
    "        E_S3 = 6*(np.inner(lamda, (1/mu)**3) -\n",
    "                  (lamda[mCl]*(1/mu[mCl])**3))/(sum(lamda)-lamda[mCl])  # checked\n",
    "\n",
    "        # calculate inputs for to check neccesity condtion:\n",
    "        varA = E_S2-E_S1**2\n",
    "        cA = math.sqrt(varA)/E_S1\n",
    "\n",
    "        # to check if all of the service rates of approximated service are same\n",
    "        # if it is true sum of hyperexpo with same parameter is ---> exponential distribution\n",
    "\n",
    "        mu_copy = []\n",
    "        mu_copy[:] = mu\n",
    "        del mu_copy[mCl]\n",
    "\n",
    "        if isServiceRateEqual(mu_copy) is True:\n",
    "            # we can assume there is only aggreate remaing streams to one rather than two\n",
    "            p = 1\n",
    "            v1 = mu_copy[0]\n",
    "\n",
    "            lam1 = lamda[mCl]\n",
    "            # S1=1/mu[mCl]\n",
    "\n",
    "            lamA1 = p*(sum(lamda)-lamda[mCl])\n",
    "            # SA1=1/float(v1)\n",
    "\n",
    "            # if sum(lamda/mu)>nservers:\n",
    "            #    nservers\n",
    "            # we have only two streams now so mClasses=2\n",
    "            marginalLength, ENLength, VarLength = MMCsolver(np.array(\n",
    "                [lam1, lamA1]), np.array([mu[mCl], v1]), nservers=nServers, mClasses=2)\n",
    "\n",
    "            marginalN.append(marginalLength[0])\n",
    "            EN.append(ENLength[0])\n",
    "            VarN.append(VarLength[0])\n",
    "\n",
    "        # if (E_S3-(3.0/2.0)*((1+cA**2)**2)*E_S1**3)<0.0:\n",
    "        # E_S3=(3.0/2.0)*((1+cA**2)**2)*E_S1**3+0.01\n",
    "        #    print \"aaa\"\n",
    "        #    v1, v2, p=whittApprox(E_S1, E_S2, E_S3)\n",
    "\n",
    "        else:\n",
    "            # a2 calculation\n",
    "            a2 = (6*E_S1-(3*E_S2/E_S1))/((6*E_S2**2/4*E_S1)-E_S3)\n",
    "\n",
    "            # a1 calculation\n",
    "            a1 = (1/E_S1)+(a2*E_S2/(2*E_S1))\n",
    "\n",
    "            # v1 calculation\n",
    "            v1 = (1.0/2.0)*(a1+math.sqrt(a1**2-4*a2))\n",
    "\n",
    "            # v2 calculation\n",
    "            v2 = (1.0/2.0)*(a1-math.sqrt(a1**2-4*a2))\n",
    "\n",
    "            # p calculation\n",
    "            p = 1-((v2*(E_S1*v1-1))/float((v1-v2)))\n",
    "\n",
    "            lam1 = lamda[mCl]\n",
    "            # S1=1/mu[mCl]\n",
    "\n",
    "            lamA1 = p*(sum(lamda)-lamda[mCl])\n",
    "            # SA1=1/float(v1)\n",
    "\n",
    "            lamA2 = (1-p)*(sum(lamda)-lamda[mCl])\n",
    "            # SA2=1/float(v2)\n",
    "\n",
    "            # Now we have 3 classes of streams (2 streams for approximation) as usual\n",
    "            # so mClasses=3\n",
    "\n",
    "            marginalLength, ENLength, VarLength = MMCsolver(np.array(\n",
    "                [lam1, lamA1, lamA2]), np.array([mu[mCl], v1, v2]), nservers=nServers, mClasses=3)\n",
    "\n",
    "            marginalN.append(marginalLength[0])\n",
    "            EN.append(ENLength[0])\n",
    "            VarN.append(VarLength[0])\n",
    "\n",
    "    return marginalN, EN, VarN\n",
    "\n",
    "\n",
    "def Approx_MMCsolver2(lamda, mu, nservers, mClasses):\n",
    "    '''\n",
    "    inputs: lamda->failure rates of SKUs\n",
    "            mu ->service rates of servers for SKUs\n",
    "            nservers->number of servers in repairshop\n",
    "            mClasses->number of SKUs := length of failure rates\n",
    "    output: Marginal Queue length for each type of SKU\n",
    "            Expected Queue length  ''  ''   ''   ''\n",
    "            Variance of Queue length ''  '' ''   ''\n",
    "    solution: Approximate 3 class system and calls MMCsolver\n",
    "    '''\n",
    "\n",
    "    # print nservers\n",
    "    marginalN = []\n",
    "    EN = []\n",
    "    VarN = []\n",
    "\n",
    "    for mCl in range(mClasses):\n",
    "        # first moment for service time distribution for approximation:\n",
    "        E_S1 = (np.inner(lamda, 1/mu)-(lamda[mCl]*1/mu[mCl]))/(sum(lamda)-lamda[mCl])  # checked\n",
    "        # print E_S1\n",
    "        # second moment\n",
    "        E_S2 = 2*(np.inner(lamda, (1/mu)**2) -\n",
    "                  (lamda[mCl]*(1/mu[mCl])**2))/(sum(lamda)-lamda[mCl])  # checked\n",
    "\n",
    "        # third moment\n",
    "        E_S3 = 6*(np.inner(lamda, (1/mu)**3) -\n",
    "                  (lamda[mCl]*(1/mu[mCl])**3))/(sum(lamda)-lamda[mCl])  # checked\n",
    "\n",
    "        # calculate inputs for to check neccesity condtion:\n",
    "        varA = E_S2-E_S1**2\n",
    "        cA = math.sqrt(varA)/E_S1\n",
    "\n",
    "        assert (E_S3-(3.0/2.0)*((1+cA**2)**2)*E_S1**3) > 0\n",
    "\n",
    "        # to check if all of the service rates of approximated service are same\n",
    "        # if it is true sum of hyperexpo with same parameter is ---> exponential distribution\n",
    "\n",
    "        mu_copy = []\n",
    "        mu_copy[:] = mu\n",
    "        del mu_copy[mCl]\n",
    "\n",
    "        if isServiceRateEqual(mu_copy) is True:\n",
    "            # we can assume there is only aggreate remaing streams to one rather than two\n",
    "            p = 1\n",
    "            v1 = mu_copy[0]\n",
    "\n",
    "            lam1 = lamda[mCl]\n",
    "            # S1=1/mu[mCl]\n",
    "\n",
    "            lamA1 = p*(sum(lamda)-lamda[mCl])\n",
    "            # SA1=1/float(v1)\n",
    "\n",
    "            # sum(lamda/mu)<nservers\n",
    "\n",
    "            if sum(np.array([lam1, lamA1])/np.array([mu[mCl], v1])) > nservers:\n",
    "                # print \"hasan\"\n",
    "                nservers = int(sum(np.array([lam1, lamA1])/np.array([mu[mCl], v1])))+1\n",
    "\n",
    "            # we have only two streams now so mClasses=2\n",
    "            marginalLength, ENLength, VarLength = MMCsolver(np.array(\n",
    "                [lam1, lamA1]), np.array([mu[mCl], v1]), nservers, mClasses=2)\n",
    "\n",
    "            marginalN.append(marginalLength[0])\n",
    "            EN.append(ENLength[0])\n",
    "            VarN.append(VarLength[0])\n",
    "            # print \"aaaa\"\n",
    "\n",
    "        # if (E_S3-(3.0/2.0)*((1+cA**2)**2)*E_S1**3)<0.0:\n",
    "        # E_S3=(3.0/2.0)*((1+cA**2)**2)*E_S1**3+0.01\n",
    "        #    print \"aaa\"\n",
    "        #    v1, v2, p=whittApprox(E_S1, E_S2, E_S3)\n",
    "\n",
    "        else:\n",
    "\n",
    "            v1, v2, p = whittApprox(E_S1, E_S2, E_S3)\n",
    "            # print v1\n",
    "            # print v2\n",
    "\n",
    "            lam1 = lamda[mCl]\n",
    "            # S1=1/mu[mCl]\n",
    "\n",
    "            lamA1 = p*(sum(lamda)-lamda[mCl])\n",
    "            # SA1=1/float(v1)\n",
    "\n",
    "            lamA2 = (1-p)*(sum(lamda)-lamda[mCl])\n",
    "            # SA2=1/float(v2)\n",
    "\n",
    "            if sum(np.array([lam1, lamA1, lamA2])/np.array([mu[mCl], v1, v2])) >= nservers:\n",
    "                # print \"turan\"\n",
    "                nservers = int(sum(np.array([lam1, lamA1, lamA2])/np.array([mu[mCl], v1, v2])))+1\n",
    "            # Now we have 3 classes of streams (2 streams for approximation) as usual\n",
    "            # so mClasses=3\n",
    "\n",
    "            marginalLength, ENLength, VarLength = MMCsolver(np.array(\n",
    "                [lam1, lamA1, lamA2]), np.array([mu[mCl], v1, v2]), nservers, mClasses=3)\n",
    "\n",
    "            marginalN.append(marginalLength[0])\n",
    "            EN.append(ENLength[0])\n",
    "            VarN.append(VarLength[0])\n",
    "\n",
    "    return marginalN, EN, VarN, nservers\n",
    "\n",
    "\n",
    "# code for optimization inventories after given queue length distribution\n",
    "def OptimizeStockLevelsAndCosts(holdingCosts, penalty, marginalDistribution):\n",
    "\n",
    "    if not isinstance(holdingCosts, np.ndarray):\n",
    "        holdingCosts = np.array(holdingCosts)\n",
    "\n",
    "    if len(marginalDistribution.shape) == 1:\n",
    "        marginalDistribution = marginalDistribution.reshape(1, len(marginalDistribution))\n",
    "\n",
    "    nSKUs = len(holdingCosts)\n",
    "    maxQueue = marginalDistribution.shape[1]\n",
    "    n_array = np.array(range(maxQueue))\n",
    "    S = np.zeros(nSKUs, dtype=int)\n",
    "    PBO = np.sum(marginalDistribution[:, 1:], axis=1)\n",
    "    EBO = np.sum(marginalDistribution*np.array(range(marginalDistribution.shape[1])), axis=1)\n",
    "\n",
    "    hb_ratio = holdingCosts/penalty\n",
    "    for sk in range(nSKUs):\n",
    "        while S[sk] < maxQueue and np.sum(marginalDistribution[sk, S[sk]+1:]) > hb_ratio[sk]:\n",
    "            S[sk] += 1\n",
    "            # -= marginalDistribution[sk, S[sk]]\n",
    "            PBO[sk] = np.sum(marginalDistribution[sk, S[sk]+1:])\n",
    "            EBO[sk] = np.sum(marginalDistribution[sk, S[sk]:]*n_array[:-S[sk]])  # -= PBO[sk]\n",
    "\n",
    "    totalCost = np.sum(S*holdingCosts) + np.sum(penalty*EBO)\n",
    "    hCost = np.sum(S*holdingCosts)\n",
    "    pCost = np.sum(penalty*EBO)\n",
    "    # print ((EBO < 0).sum() == EBO.size).astype(np.int)\n",
    "    # if pCost<0.0:\n",
    "    #    print EBO\n",
    "    # print  ((EBO < 0).sum() == EBO.size).astype(np.int)\n",
    "    # print all(i >= 0.0 for i in marginalDistribution)\n",
    "\n",
    "    return totalCost, hCost, pCost, S, EBO\n",
    "\n",
    "\n",
    "def individual2cluster(individual):\n",
    "    '''\n",
    "    -input: list of integers representing assingment of SKUs to clusters\n",
    "    -output: list of list representing clusters and assinged SKUs in each cluster\n",
    "    '''\n",
    "    return [[i + 1 for i, j in enumerate(individual) if j == x] for x in set(individual)]\n",
    "\n",
    "\n",
    "def evalOneMax(FailureRates, ServiceRates, holding_costs, penalty_cost, skillCost, machineCost, individual):\n",
    "    '''\n",
    "    input: -Individual representing clustering scheme\n",
    "           -Failure rates and corresponding service rates of each SKU\n",
    "           -Related cost terms holding costs for SKUs(array), backorder, skill and server (per server and per skill)\n",
    "           -MMCsolver and Approx_MMCsolver functions--> to find Queue length dist. of failed SKUs\n",
    "                                                    --> number of SKUS >=4 use approximation\n",
    "           -OptimizeStockLevels calculates EBO and S for giving clustering (Queue length dist.)\n",
    "     output: Returns best total cost and other cost terms, Expected backorder (EBO) and stocks (S) for each SKU, # of\n",
    "             servers at each cluster\n",
    "     evalOneMax function evaluates the fitness of individual chromosome by:\n",
    "           (1) chromosome converted a clustering scheme\n",
    "           (2) for each SKU in each cluster at the clustering scheme queue length dist. evaluated by calling MMC solver\n",
    "           (3) OptimzeStockLevels function is called by given queue length dist. and initial costs are calculated\n",
    "           (4) Local search is performed by increasing server numbers in each cluster by one and step (2) and (3) repetead\n",
    "           (5) Step (4) is repated if there is a decrease in total cost\n",
    "    Warning !! type matching array vs list might be problem (be careful about type matching)\n",
    "    '''\n",
    "\n",
    "    # from individual to cluster\n",
    "    cluster_GA = individual2cluster(individual)\n",
    "    # bestCost=float('inf')\n",
    "    # bestCluster=[]\n",
    "    # print \"\\n\"\n",
    "    # print individual\n",
    "    # print cluster_GA\n",
    "\n",
    "    bestS = []\n",
    "    bestEBO = []\n",
    "    EBO_cluster = []\n",
    "    S_cluster = []\n",
    "    bestserverAssignment = []\n",
    "    serverAssignment = []\n",
    "    sliceIndex2 = []\n",
    "    TotalCost = 0.0\n",
    "    TotalHolding, TotalPenalty, TotalSkillCost, TotalMachineCost = 0.0, 0.0, 0.0, 0.0\n",
    "    # LogFileList=[]\n",
    "    # logFile={}\n",
    "    # iterationNum=0\n",
    "    for cluster in cluster_GA:\n",
    "        sliceIndex2[:] = cluster\n",
    "        sliceIndex2[:] = [x - 1 for x in sliceIndex2]\n",
    "\n",
    "        sRate = np.array(ServiceRates[sliceIndex2])\n",
    "        fRate = np.array(FailureRates[sliceIndex2])\n",
    "        hcost = np.array(holding_costs[sliceIndex2])\n",
    "\n",
    "        min_nserver = int(sum(fRate/sRate))+1\n",
    "        # print sliceIndex2\n",
    "        # print \"RUn FINISHED \\n\"\n",
    "        # sys.exit(0)\n",
    "        # costTemp=0\n",
    "        # while costTemp<=machineCost:\n",
    "        if len(sRate) <= 3:\n",
    "            marginalDist, EN, VarN = MMCsolver(fRate, sRate, min_nserver, len(fRate))\n",
    "        else:\n",
    "            marginalDist, EN, VarN, min_nserverUpdate = Approx_MMCsolver2(\n",
    "                fRate, sRate, min_nserver, len(fRate))\n",
    "            min_nserver = min_nserverUpdate\n",
    "\n",
    "        totalCostClust, hCost, pCost, S, EBO = OptimizeStockLevelsAndCosts(\n",
    "            hcost, penalty_cost, np.array(marginalDist))\n",
    "\n",
    "        # increasing number of servers and checking if total cost decreases\n",
    "\n",
    "        TotalMachine_Cost = min_nserver*machineCost\n",
    "        TotalSkill_Cost = min_nserver*len(fRate)*skillCost\n",
    "\n",
    "        totalCostClust = totalCostClust+TotalMachine_Cost+TotalSkill_Cost\n",
    "\n",
    "        while True:\n",
    "            min_nserver += 1\n",
    "            if len(sRate) <= 3:\n",
    "                marginalDist, EN, VarN = MMCsolver(fRate, sRate, min_nserver, len(fRate))\n",
    "            else:\n",
    "                marginalDist, EN, VarN, min_nserverUpdate = Approx_MMCsolver2(\n",
    "                    fRate, sRate, min_nserver, len(fRate))\n",
    "                min_nserver = min_nserverUpdate\n",
    "\n",
    "            temp_totalCostClust, temp_hCost, temp_pCost, temp_S, temp_EBO = OptimizeStockLevelsAndCosts(\n",
    "                hcost, penalty_cost, np.array(marginalDist))\n",
    "            temp_TotalMachine_Cost = min_nserver*machineCost\n",
    "            temp_TotalSkill_Cost = min_nserver*len(fRate)*skillCost\n",
    "\n",
    "            temp_totalCostClust = temp_totalCostClust+temp_TotalMachine_Cost+temp_TotalSkill_Cost\n",
    "\n",
    "            if temp_totalCostClust > totalCostClust:\n",
    "                min_nserver -= 1\n",
    "                break\n",
    "            else:\n",
    "                totalCostClust = temp_totalCostClust\n",
    "\n",
    "                TotalMachine_Cost = temp_TotalMachine_Cost\n",
    "                TotalSkill_Cost = temp_TotalSkill_Cost\n",
    "                hCost = temp_hCost\n",
    "                pCost = temp_pCost\n",
    "\n",
    "        TotalHolding += hCost\n",
    "        TotalPenalty += pCost\n",
    "\n",
    "        TotalSkillCost += TotalSkill_Cost\n",
    "        TotalMachineCost += TotalMachine_Cost\n",
    "\n",
    "        TotalCost = TotalCost+totalCostClust\n",
    "\n",
    "        EBO_cluster.append(EBO.tolist())\n",
    "        S_cluster.append(S.tolist())\n",
    "        serverAssignment.append(min_nserver)\n",
    "\n",
    "    return TotalCost,\n",
    "\n",
    "# bestHolding, bestPenalty, bestMachineCost, bestSkillCost, bestCluster, bestS, bestEBO, \\\n",
    "#            bestserverAssignment, LogFileList\n",
    "# DONT FORGET COME AT THE END!!!\n",
    "\n",
    "\n",
    "def Final_evalOneMax(FailureRates, ServiceRates, holding_costs, penalty_cost, skillCost, machineCost, individual):\n",
    "    '''\n",
    "    input: -Individual representing clustering scheme\n",
    "           -Failure rates and corresponding service rates of each SKU\n",
    "           -Related cost terms holding costs for SKUs(array), backorder, skill and server (per server and per skill)\n",
    "           -MMCsolver and Approx_MMCsolver functions--> to find Queue length dist. of failed SKUs\n",
    "                                                    --> number of SKUS >=4 use approximation\n",
    "           -OptimizeStockLevels calculates EBO and S for giving clustering (Queue length dist.)\n",
    "     output: Returns best total cost and other cost terms, Expected backorder (EBO) and stocks (S) for each SKU, # of\n",
    "             servers at each cluster\n",
    "     evalOneMax function evaluates the fitness of individual chromosome by:\n",
    "           (1) chromosome converted a clustering scheme\n",
    "           (2) for each SKU in each cluster at the clustering scheme queue length dist. evaluated by calling MMC solver\n",
    "           (3) OptimzeStockLevels function is called by given queue length dist. and initial costs are calculated\n",
    "           (4) Local search is performed by increasing server numbers in each cluster by one and step (2) and (3) repeted\n",
    "           (5) Step (4) is repated if there is a decrease in total cost\n",
    "    Warning !! type matching array vs list might be problem (be careful about type matching)\n",
    "    '''\n",
    "\n",
    "    # from individual to cluster\n",
    "    # cluster_GA = individual2cluster(individual)\n",
    "    # bestCost=float('inf')\n",
    "    # bestCluster=[]\n",
    "    cluster_GA = individual\n",
    "    bestS = []\n",
    "    bestEBO = []\n",
    "    EBO_cluster = []\n",
    "    S_cluster = []\n",
    "    bestserverAssignment = []\n",
    "    serverAssignment = []\n",
    "    sliceIndex2 = []\n",
    "    TotalCost = 0.0\n",
    "    TotalHolding, TotalPenalty, TotalSkillCost, TotalMachineCost = 0.0, 0.0, 0.0, 0.0\n",
    "    # LogFileList=[]\n",
    "    # logFile={}\n",
    "    # iterationNum=0\n",
    "    for cluster in cluster_GA:\n",
    "        sliceIndex2[:] = cluster\n",
    "        sliceIndex2[:] = [x - 1 for x in sliceIndex2]\n",
    "\n",
    "        sRate = np.array(ServiceRates[sliceIndex2])\n",
    "        fRate = np.array(FailureRates[sliceIndex2])\n",
    "        hcost = np.array(holding_costs[sliceIndex2])\n",
    "\n",
    "        min_nserver = int(sum(fRate/sRate))+1\n",
    "\n",
    "        # costTemp=0\n",
    "        # while costTemp<=machineCost:\n",
    "        if len(sRate) <= 3:\n",
    "            marginalDist, EN, VarN = MMCsolver(fRate, sRate, min_nserver, len(fRate))\n",
    "        else:\n",
    "            marginalDist, EN, VarN, min_nserverUpdate = Approx_MMCsolver2(\n",
    "                fRate, sRate, min_nserver, len(fRate))\n",
    "            min_nserver = min_nserverUpdate\n",
    "\n",
    "        totalCostClust, hCost, pCost, S, EBO = OptimizeStockLevelsAndCosts(\n",
    "            hcost, penalty_cost, np.array(marginalDist))\n",
    "\n",
    "        # increasing number of servers and checking if total cost decreases\n",
    "\n",
    "        TotalMachine_Cost = min_nserver*machineCost\n",
    "        TotalSkill_Cost = min_nserver*len(fRate)*skillCost\n",
    "\n",
    "        totalCostClust = totalCostClust+TotalMachine_Cost+TotalSkill_Cost\n",
    "\n",
    "        while True:\n",
    "            min_nserver += 1\n",
    "            if len(sRate) <= 3:\n",
    "                marginalDist, EN, VarN = MMCsolver(fRate, sRate, min_nserver, len(fRate))\n",
    "            else:\n",
    "                marginalDist, EN, VarN, min_nserverUpdate = Approx_MMCsolver2(\n",
    "                    fRate, sRate, min_nserver, len(fRate))\n",
    "                min_nserver = min_nserverUpdate\n",
    "\n",
    "            temp_totalCostClust, temp_hCost, temp_pCost, temp_S, temp_EBO = OptimizeStockLevelsAndCosts(\n",
    "                hcost, penalty_cost, np.array(marginalDist))\n",
    "            temp_TotalMachine_Cost = min_nserver*machineCost\n",
    "            temp_TotalSkill_Cost = min_nserver*len(fRate)*skillCost\n",
    "\n",
    "            temp_totalCostClust = temp_totalCostClust+temp_TotalMachine_Cost+temp_TotalSkill_Cost\n",
    "\n",
    "            if temp_totalCostClust > totalCostClust:\n",
    "                min_nserver -= 1\n",
    "                break\n",
    "            else:\n",
    "                totalCostClust = temp_totalCostClust\n",
    "\n",
    "                TotalMachine_Cost = temp_TotalMachine_Cost\n",
    "                TotalSkill_Cost = temp_TotalSkill_Cost\n",
    "                hCost = temp_hCost\n",
    "                pCost = temp_pCost\n",
    "\n",
    "        TotalHolding += hCost\n",
    "        TotalPenalty += pCost\n",
    "\n",
    "        TotalSkillCost += TotalSkill_Cost\n",
    "        TotalMachineCost += TotalMachine_Cost\n",
    "\n",
    "        TotalCost = TotalCost+totalCostClust\n",
    "\n",
    "        EBO_cluster.append(EBO.tolist())\n",
    "        S_cluster.append(S.tolist())\n",
    "        serverAssignment.append(min_nserver)\n",
    "\n",
    "    return TotalCost, TotalHolding, TotalPenalty, TotalMachineCost, TotalSkillCost, cluster_GA, S_cluster, EBO_cluster, serverAssignment\n",
    "# DONT FORGET COME AT THE END!!!\n",
    "\n",
    "\n",
    "def swicthtoOtherMutation(individual, indpb):\n",
    "    '''\n",
    "    input- individual chromosome\n",
    "    output- some genes changed to other genes in chromosome (changing clusters)\n",
    "    There might be other ways of mutation - swaping clusters of two SKUs (crossover does that) two way swap\n",
    "                                          - opening a new cluster\n",
    "                                          - closing a cluster and allocated SKUs in that cluster to another cluster\n",
    "                                          -(local or tabu search idea!!)\n",
    "    '''\n",
    "    # to keep orginal probabilty of switching to other cluster during iteration\n",
    "    individual_copy = individual[:]\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() <= indpb:\n",
    "            if random.random() <= 1.5:  # switch only version _v4a\n",
    "                # set is used to give equal probability to assign any other cluster\n",
    "                # without set there is a higher probablity to assigning to a cluster that inclludes more SKUs\n",
    "                if len(list(set(individual_copy).difference(set([individual_copy[i]])))) >= 1:\n",
    "                    individual[i] = random.choice(\n",
    "                        list(set(individual_copy).difference(set([individual_copy[i]]))))\n",
    "\n",
    "            else:\n",
    "                # This mutation type aimed for generating new cluster and going beyond the allowed maximum num cluster\n",
    "                if len(list(set(range(1, len(individual_copy)+1)).difference(set(individual_copy)))) >= 1:\n",
    "                    individual[i] = random.choice(\n",
    "                        list(set(range(1, len(individual_copy)+1)).difference(set(individual_copy))))\n",
    "\n",
    "    return individual\n",
    "\n",
    "\n",
    "def neighborhood_solution(S, minCluster, maxCluster):\n",
    "    S_new = S[:]\n",
    "    numSKUs = len(S)    \n",
    "    # print (numSKUs, S, index_to_mutate)\n",
    "    r = random.uniform(0, 1)\n",
    "    action = 2\n",
    "    if r <= 0.33:  # mutate one \n",
    "        index_to_mutate = random.randint(0, numSKUs-1)\n",
    "        ex_cluster_number = S[index_to_mutate]\n",
    "        numbers = list(range(minCluster, ex_cluster_number)) + list(range(ex_cluster_number+1, maxCluster))\n",
    "        S_new[index_to_mutate] = random.choice(numbers)\n",
    "        action = 0\n",
    "    elif r<=0.66: # mutate two\n",
    "        idx1, idx2 = random.sample(range(0, numSKUs), 2)\n",
    "        ex_cluster_number = S[idx1]\n",
    "        numbers = list(range(minCluster, ex_cluster_number)) + list(range(ex_cluster_number + 1, maxCluster))\n",
    "        S_new[idx1] = random.choice(numbers)\n",
    "        ex_cluster_number = S[idx2]\n",
    "        numbers = list(range(minCluster, ex_cluster_number)) + list(range(ex_cluster_number + 1, maxCluster))\n",
    "        S_new[idx2] = random.choice(numbers)\n",
    "        action = 1\n",
    "    else:\n",
    "        idx1, idx2 = random.sample(range(numSKUs), 2)\n",
    "        S_new[idx1] = S[idx2]\n",
    "        S_new[idx2] = S[idx1]\n",
    "    return action, S_new\n",
    "\n",
    "def evalOneMax2(solution_database, individual):\n",
    "    '''\n",
    "    For bruteforce solution only    \n",
    "    '''\n",
    "    \n",
    "    cluster_GA = individual2cluster(individual)\n",
    "    \n",
    "    key=tuple(tuple(item) for item in sorted(cluster_GA))\n",
    "    \n",
    "    return solution_database[key],\n",
    "\n",
    "\n",
    "def GAPoolingHeuristic(case_id, solution_database, optimal_solution, optimal_value, failure_rates, service_rates, holding_costs, penalty_cost, skill_cost, machine_cost, numSKUs, minCluster, maxCluster):\n",
    "\n",
    "\n",
    "    # 1 is for maximization -1 for minimization\n",
    "    # Minimize total cost\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    def generateIndividual(numSKUs, minCluster, maxCluster):\n",
    "\n",
    "        # Generating initial indvidual that are in the range of given max-min cluster numbers\n",
    "\n",
    "        individual = [0]*numSKUs\n",
    "\n",
    "        randomSKUsindex = np.random.choice(range(numSKUs), minCluster, replace=False)\n",
    "        cluster_randomSKUs = np.random.choice(range(1, maxCluster+1), minCluster, replace=False)\n",
    "\n",
    "        for i in range(minCluster):\n",
    "            individual[randomSKUsindex[i]] = cluster_randomSKUs[i]\n",
    "\n",
    "        for i in range(numSKUs):\n",
    "            if individual[i] == 0:\n",
    "                individual[i] = random.randint(1, maxCluster)\n",
    "\n",
    "        # print type (creator.Individual(individual))\n",
    "        return creator.Individual(individual)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # Attribute generator\n",
    "    #                      define 'attr_bool' to be an attribute ('gene')\n",
    "    #                      which corresponds to integers sampled uniformly\n",
    "    #                      from the range [1,number of SKUs] (i.e. 0 or 1 with equal\n",
    "    #                      probability)\n",
    "\n",
    "    # Structure initializers\n",
    "    #                         define 'individual' to be an individual\n",
    "    #                         consisting of #number of maximum cluster =#of SKUs 'attr_bool' elements ('genes')\n",
    "    toolbox.register(\"individual\", generateIndividual, numSKUs, minCluster, maxCluster)\n",
    "\n",
    "    # define the population to be a list of individuals\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    # the goal ('fitness') function to be maximized\n",
    "    # for objective function call pooling optimizer !!!\n",
    "    # what values need for optimizer !!!\n",
    "\n",
    "    # def evalOneMax(individual):\n",
    "    #    return sum(individual),\n",
    "\n",
    "    # ----------\n",
    "    # Operator registration\n",
    "    # ----------\n",
    "    # register the goal / fitness function modified for bruteforce\n",
    "    toolbox.register(\"evaluate\", evalOneMax2, solution_database)\n",
    "\n",
    "    # register the crossover operator\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "\n",
    "    # register a mutation operator with a probability to\n",
    "    # flip each attribute/gene of 0.05\n",
    "    #\n",
    "    toolbox.register(\"mutate\", swicthtoOtherMutation, indpb=0.4)\n",
    "    # toolbox.register(\"mutate\", swicthtoOtherMutation)\n",
    "\n",
    "    # operator for selecting individuals for breeding the next\n",
    "    # generation: each individual of the current generation\n",
    "    # is replaced by the 'fittest' (best) of three individuals\n",
    "    # drawn randomly from the current generation.\n",
    "\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=10)\n",
    "\n",
    "    # create an initial population of 100 individuals (where\n",
    "    # each individual is a list of integers)\n",
    "\n",
    "    start_time = time.time() #start time\n",
    "    pop = toolbox.population(n=1)\n",
    "    # Evaluate the entire population\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))    \n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    # Extracting all the fitnesses of \n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "    best_cost=min(fits)\n",
    "    S_best=tools.selBest(pop, 1)[0]\n",
    "    \n",
    "\n",
    "    # RL Parameters\n",
    "    batch_size = 32\n",
    "    gamma = 0.999\n",
    "    eps_start = 1\n",
    "    eps_end = 0.01\n",
    "    eps_decay = 0.001\n",
    "    target_update = 10\n",
    "    memory_size = 100000\n",
    "    lr = 0.001\n",
    "    num_episodes = 300\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    em = EnvironmentManager(device, S_best, minCluster, maxCluster, toolbox.evaluate)\n",
    "    strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay)\n",
    "    agent = Agent(strategy, em.num_actions_available(), device)\n",
    "    memory = ReplayMemory(memory_size)\n",
    "\n",
    "    policy_net = DQN(len(S_best),em.num_actions_available()).to(device)\n",
    "    target_net = DQN(len(S_best),em.num_actions_available()).to(device)\n",
    "\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()  # don't train target net\n",
    "    optimizer = optim.Adam(params=policy_net.parameters(), lr=lr)\n",
    "    \n",
    "    steps_RL = 128\n",
    "    tc_best = best_cost\n",
    "    best_s_x = S_best\n",
    "    best_rl_s_x = S_best\n",
    "    best_rl_cost = best_cost\n",
    "    new_best_found = False\n",
    "    steps_SA = 1000\n",
    "\n",
    "    print(\"lr:\", lr)\n",
    "    print(\"num episodes:\", num_episodes)\n",
    "    print(\"batch_size\", batch_size)\n",
    "    print(\"steps SA\", steps_SA)\n",
    "    print(\"steps RL\", steps_RL)\n",
    "\n",
    "    for episode in tqdm(range(1, num_episodes+1), desc=\"Episode\"):   \n",
    "        new_best_found = False\n",
    "        total_rewards = 0\n",
    "        total_loss =0\n",
    "        # em.reset()\n",
    "        state = em.get_state()   # state is the solution S\n",
    "        # run RL for a number of steps\n",
    "        for timestep in range(1, steps_RL+1):\n",
    "            # select action\n",
    "            action = agent.select_action(state, policy_net)  \n",
    "            # get reward\n",
    "            new_cost, reward = em.take_action(action)\n",
    "            total_rewards += reward.item()\n",
    "            # get next state\n",
    "            next_state = em.get_state()\n",
    "            # store experience in replay memory\n",
    "            memory.push(Experience(torch.FloatTensor(state)/numSKUs, action, torch.FloatTensor(next_state)/numSKUs, reward))\n",
    "            # switch to next state\n",
    "            state = next_state\n",
    "            if new_cost <= best_rl_cost:\n",
    "                best_rl_cost = new_cost\n",
    "                best_rl_s_x = state\n",
    "                new_best_found = True\n",
    "            # optimize policy network\n",
    "            if memory.can_provide_sample(batch_size):\n",
    "                experiences = memory.sample(batch_size)\n",
    "                states, actions, rewards, next_states = extract_tensors(experiences)\n",
    "\n",
    "                current_q_values = QValues.get_current(policy_net, states, actions)  # current q values q(s,a)\n",
    "                next_q_values = QValues.get_next(target_net, next_states)  # max term of bellman equation\n",
    "                target_q_values = (next_q_values * gamma) + rewards  # optimal q values --> q*(s,a)\n",
    "\n",
    "                loss = F.mse_loss(current_q_values, target_q_values.unsqueeze(1))  # loss = q*(s,a) - q(s,a)\n",
    "                total_loss += loss.item()\n",
    "                # print(\"Loss \", loss.data)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        if episode % target_update == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        # print(f\"{bcolors.OKBLUE}Total Reward: {total_rewards:.2f} Total Loss: {total_loss:.2f}{bcolors.ENDC}\")\n",
    "        \n",
    "        if new_best_found :\n",
    "            s_x = best_rl_s_x[0]        \n",
    "        else:\n",
    "            s_x = state[0]\n",
    "        tc_s_x = toolbox.evaluate(s_x)[0]\n",
    "        tm = 5\n",
    "        T=tm\n",
    "        t0 = 100000\n",
    "        a = -math.log(T/t0)\n",
    "        y = steps_SA\n",
    "        q=0\n",
    "        #print(\"---SA---\") \n",
    "        for t in range(y):         \n",
    "            action, s_prime = neighborhood_solution(s_x, minCluster, maxCluster)\n",
    "            tc_sprime = toolbox.evaluate(s_prime)[0]\n",
    "            delta_E = tc_sprime - tc_s_x\n",
    "            memory.push(Experience(torch.FloatTensor([s_x])/numSKUs, torch.tensor([action]), torch.FloatTensor([s_prime])/numSKUs, torch.FloatTensor([-delta_E])))\n",
    "            if delta_E <= 0:\n",
    "                # print (\"Better neighbour found at itr= {}\".format(itr))\n",
    "                s_x = s_prime\n",
    "                tc_s_x = tc_sprime\n",
    "                if tc_sprime < tc_best:\n",
    "                    print(f\"{bcolors.OKGREEN}Better Cost {tc_sprime} t= {t}{bcolors.ENDC}\")\n",
    "                    tc_best = tc_sprime\n",
    "                    S_best = s_x\n",
    "            else:\n",
    "                r = random.uniform(0, 1)\n",
    "                if r < math.exp(-delta_E / T):\n",
    "                    s_x = s_prime\n",
    "                    tc_s_x = tc_sprime\n",
    "\n",
    "            T = tm * math.exp(a*q/y)\n",
    "            q += 1\n",
    "        assert t==y-1\n",
    "        # SA finished\n",
    "        best_rl_s_x = S_best\n",
    "        best_rl_cost = tc_best\n",
    "        em.setState(S_best)\n",
    "\n",
    "    pop[0] = creator.Individual(S_best)\n",
    "    TCs = list(map(toolbox.evaluate, pop))\n",
    "    for ind, tc in zip(pop, TCs):\n",
    "        ind.fitness.values = tc\n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    # print(\"Best individual is %s, %s\" % (individual2cluster(best_ind), best_ind.fitness.values))\n",
    "    return best_ind.fitness.values, best_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lr: 0.001\nnum episodes: 300\nbatch_size 32\nsteps SA 1000\nsteps RL 128\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f8b1fe0e5d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mnumSKUs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminCluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxCluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailure_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailure_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         best_val, best_ind = GAPoolingHeuristic(case[\"caseID\"], solution_database, optimal_solution, optimal_value, np.array(failure_rates), np.array(service_rates),\n\u001b[0;32m---> 43\u001b[0;31m                                      np.array(holding_costs), penalty_cost, skill_cost, machine_cost, numSKUs, minCluster, maxCluster)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-38a06fac9ee7>\u001b[0m in \u001b[0;36mGAPoolingHeuristic\u001b[0;34m(case_id, solution_database, optimal_solution, optimal_value, failure_rates, service_rates, holding_costs, penalty_cost, skill_cost, machine_cost, numSKUs, minCluster, maxCluster)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"steps RL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_RL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Episode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[0mnew_best_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0mtotal_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "file = \"fullRangeResultsFullFlexNew.json\"\n",
    "json_case = [json.loads(line) for line in open(file, \"r\")]\n",
    "sorted_assignments = sorted(json_case, key=operator.itemgetter('caseID'))\n",
    "json_cases = sorted_assignments[:]\n",
    "#for case in json_cases:\n",
    "#    print (case[\"caseID\"])\n",
    "\n",
    "# RUN of ALgorithm STARTS HERE ##\n",
    "# json_case\n",
    "results = []\n",
    "GAPoolingResult = {}\n",
    "case_idx = 0\n",
    "\n",
    "problem_size_set=[5,6,7]\n",
    "\n",
    "for problem_size in problem_size_set:\n",
    "    problem_counter=0\n",
    "    for case in json_cases:\n",
    "    # \n",
    "        if case[\"caseID\"] != \"Case: 000x\":\n",
    "            failure_rates = case[\"failure_rates\"][:problem_size]\n",
    "            service_rates = case[\"service_rates\"][:problem_size]\n",
    "            holding_costs = case[\"holding_costs\"][:problem_size]\n",
    "            skill_cost = case[\"skill_cost\"]\n",
    "            penalty_cost = case[\"penalty_cost\"]\n",
    "            machine_cost = case[\"machine_cost\"]\n",
    "            # print (case[\"caseID\"], \" is runnig\")\n",
    "        start_time = time.time()\n",
    "        solution_database={}\n",
    "        stop_time = time.time() - start_time\n",
    "        something = list(range(1,problem_size+1))\n",
    "        for n, p in enumerate(partition(something), 1):\n",
    "            bestCost, bestHolding, bestPenalty, bestMachineCost, bestSkillCost, bestCluster, bestS, bestEBO, bestserverAssignment = Final_evalOneMax(np.array(failure_rates), np.array(service_rates), np.array(holding_costs), penalty_cost, skill_cost, machine_cost, p)\n",
    "            #record data base\n",
    "            key=tuple(tuple(item) for item in sorted(p))\n",
    "            solution_database[key]=bestCost\n",
    "            #print n, p, bestCost\n",
    "        optimal_solution=min(solution_database, key=solution_database.get) \n",
    "        optimal_value=solution_database[optimal_solution]\n",
    "        #Now Call MTSA with Database\n",
    "        numSKUs, minCluster, maxCluster = len(failure_rates), 1, len(failure_rates)\n",
    "        best_val, best_ind = GAPoolingHeuristic(case[\"caseID\"], solution_database, optimal_solution, optimal_value, np.array(failure_rates), np.array(service_rates),\n",
    "                                     np.array(holding_costs), penalty_cost, skill_cost, machine_cost, numSKUs, minCluster, maxCluster)\n",
    "    \n",
    "    \n",
    "        #print best_ind, optimal_solution\n",
    "        gap=100*abs(best_val-optimal_value)/best_val\n",
    "        print(\"Best Found:\", best_val, \"Optimal:\", optimal_value, \"GAP:\", gap[0])\n",
    "        problem_counter=problem_counter+1        \n",
    "        case_idx += 1\n",
    "        with open('optimality_gap_2.csv', 'a') as csvfile:\n",
    "            fieldnames = ['case_id', \"SKU_size\", 'brute_force_solution', 'brute_force_optimal', 'RLSA_solution',\n",
    "                     'RLSA_optimal', \"GAP\"]\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "            if case_idx == 1:\n",
    "                writer.writeheader()\n",
    "            writer.writerow({'case_id': case[\"caseID\"],\"SKU_size\": problem_size, 'brute_force_solution': optimal_solution,\n",
    "                        'brute_force_optimal': optimal_value, 'RLSA_solution': best_ind,\n",
    "                        'RLSA_optimal': best_val, \"GAP\": gap[0]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2), (3, 4, 6, 7, 8), (5,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'S_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5b85b14d4100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mS_best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'S_best' is not defined"
     ]
    }
   ],
   "source": [
    "S_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('p37': conda)",
   "language": "python",
   "name": "python37264bitp37conda40bdd08730654a3489938532f8989fa4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}